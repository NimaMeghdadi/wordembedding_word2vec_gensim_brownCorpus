{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : PROGRESS: at sentence #10000, processed 219770 words, keeping 23488 word types\n",
      "INFO : PROGRESS: at sentence #20000, processed 430477 words, keeping 34367 word types\n",
      "INFO : PROGRESS: at sentence #30000, processed 669056 words, keeping 42365 word types\n",
      "INFO : PROGRESS: at sentence #40000, processed 888291 words, keeping 49136 word types\n",
      "INFO : PROGRESS: at sentence #50000, processed 1039920 words, keeping 53024 word types\n",
      "INFO : collected 56057 word types from a corpus of 1161192 raw words and 57340 sentences\n",
      "INFO : Creating a fresh vocabulary\n",
      "INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 15173 unique words (27.07% of original 56057, drops 40884)', 'datetime': '2023-04-12T01:53:09.742860', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1095086 word corpus (94.31% of original 1161192, drops 66106)', 'datetime': '2023-04-12T01:53:09.745883', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO : deleting the raw counts dictionary of 56057 items\n",
      "INFO : sample=0.001 downsamples 42 most-common words\n",
      "INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 781596.5348479215 word corpus (71.4%% of prior 1095086)', 'datetime': '2023-04-12T01:53:10.040384', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO : estimated required memory for 15173 words and 300 dimensions: 44001700 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-12T01:53:10.406945', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 15173 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=20 window=15 shrink_windows=True', 'datetime': '2023-04-12T01:53:10.409946', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "INFO : EPOCH 0 - PROGRESS: at 8.01% examples, 63047 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 19.95% examples, 80262 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 35.48% examples, 94681 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 49.43% examples, 101695 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 61.21% examples, 101787 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 77.47% examples, 102866 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 96.96% examples, 104559 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0: training on 1161192 raw words (781573 effective words) took 7.5s, 104779 effective words/s\n",
      "INFO : EPOCH 1 - PROGRESS: at 15.37% examples, 120083 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 30.18% examples, 117821 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 42.29% examples, 112255 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 55.32% examples, 113917 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 73.02% examples, 119202 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 89.23% examples, 114370 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 1: training on 1161192 raw words (781650 effective words) took 6.7s, 116221 effective words/s\n",
      "INFO : EPOCH 2 - PROGRESS: at 11.48% examples, 92030 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 23.64% examples, 93188 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 36.33% examples, 96863 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 47.85% examples, 98387 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 61.85% examples, 103862 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 75.14% examples, 101128 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 87.02% examples, 96557 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 96.96% examples, 91020 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 2: training on 1161192 raw words (780992 effective words) took 8.6s, 90401 effective words/s\n",
      "INFO : EPOCH 3 - PROGRESS: at 8.81% examples, 69108 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 18.20% examples, 74267 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 29.46% examples, 76898 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 41.53% examples, 83286 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 53.82% examples, 88768 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 67.44% examples, 93979 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 82.18% examples, 92407 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 96.96% examples, 91751 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 3: training on 1161192 raw words (781236 effective words) took 8.5s, 92077 effective words/s\n",
      "INFO : EPOCH 4 - PROGRESS: at 8.01% examples, 62367 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 18.20% examples, 73731 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 30.18% examples, 78939 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 40.69% examples, 82211 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 53.82% examples, 88408 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 65.57% examples, 90932 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 82.18% examples, 92203 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 95.75% examples, 90328 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 4: training on 1161192 raw words (781444 effective words) took 8.7s, 90267 effective words/s\n",
      "INFO : Word2Vec lifecycle event {'msg': 'training on 5805960 raw words (3906895 effective words) took 40.0s, 97663 effective words/s', 'datetime': '2023-04-12T01:53:50.416985', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=15173, vector_size=300, alpha=0.025>', 'datetime': '2023-04-12T01:53:50.419003', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "dim = [25, 100, 300]\n",
    "wind = [2, 7, 15]\n",
    "neg = [1, 7, 20]\n",
    "model = gensim.models.Word2Vec(brown.sents(),\n",
    "                                vector_size=300,\n",
    "                                window=15,\n",
    "                                negative=20\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : Word2Vec lifecycle event {'fname_or_handle': './model/brown.embedding', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-12T01:59:04.246204', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'saving'}\n",
      "INFO : not storing attribute cum_table\n",
      "INFO : saved ./model/brown.embedding\n",
      "INFO : loading Word2Vec object from ./model/brown.embedding\n",
      "INFO : loading wv recursively from ./model/brown.embedding.wv.* with mmap=None\n",
      "INFO : setting ignored attribute cum_table to None\n",
      "INFO : Word2Vec lifecycle event {'fname': './model/brown.embedding', 'datetime': '2023-04-12T01:59:04.735084', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "model.save('./model/brown.embedding')\n",
    "new_model = gensim.models.Word2Vec.load('./model/brown.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('academic', 0.9136051535606384),\n",
       " ('arts', 0.9083114862442017),\n",
       " ('universities', 0.9009261131286621),\n",
       " ('aspects', 0.8994946479797363),\n",
       " ('participation', 0.8973093628883362),\n",
       " ('college', 0.8937174081802368),\n",
       " ('Christianity', 0.8912739753723145),\n",
       " ('membership', 0.8909777998924255),\n",
       " ('trend', 0.8905456066131592),\n",
       " ('culture', 0.8888988494873047)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.wv.most_similar(\"university\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76638937"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(new_model['university'])\n",
    "new_model.wv.similarity('university','school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : Skipping line #6 with OOV words: computer\tkeyboard\t7.62\n",
      "INFO : Skipping line #7 with OOV words: computer\tinternet\t7.58\n",
      "INFO : Skipping line #15 with OOV words: cucumber\tpotato\t5.92\n",
      "INFO : Skipping line #34 with OOV words: professor\tcucumber\t0.31\n",
      "INFO : Skipping line #35 with OOV words: king\tcabbage\t0.23\n",
      "INFO : Skipping line #37 with OOV words: king\trook\t5.92\n",
      "INFO : Skipping line #40 with OOV words: Jerusalem\tPalestinian\t7.65\n",
      "INFO : Skipping line #42 with OOV words: fuck\tsex\t9.44\n",
      "INFO : Skipping line #43 with OOV words: Maradona\tfootball\t8.62\n",
      "INFO : Skipping line #44 with OOV words: football\tsoccer\t9.03\n",
      "INFO : Skipping line #48 with OOV words: Arafat\tpeace\t6.73\n",
      "INFO : Skipping line #49 with OOV words: Arafat\tterror\t7.65\n",
      "INFO : Skipping line #50 with OOV words: Arafat\tJackson\t2.50\n",
      "INFO : Skipping line #53 with OOV words: movie\tpopcorn\t6.19\n",
      "INFO : Skipping line #56 with OOV words: physics\tproton\t8.12\n",
      "INFO : Skipping line #60 with OOV words: vodka\tgin\t8.46\n",
      "INFO : Skipping line #61 with OOV words: vodka\tbrandy\t8.13\n",
      "INFO : Skipping line #69 with OOV words: gem\tjewel\t8.96\n",
      "INFO : Skipping line #73 with OOV words: asylum\tmadhouse\t8.87\n",
      "INFO : Skipping line #74 with OOV words: magician\twizard\t9.02\n",
      "INFO : Skipping line #79 with OOV words: bird\tcrane\t7.38\n",
      "INFO : Skipping line #80 with OOV words: tool\timplement\t6.46\n",
      "INFO : Skipping line #82 with OOV words: crane\timplement\t2.69\n",
      "INFO : Skipping line #85 with OOV words: monk\toracle\t5.00\n",
      "INFO : Skipping line #86 with OOV words: cemetery\twoodland\t2.08\n",
      "INFO : Skipping line #87 with OOV words: food\trooster\t4.42\n",
      "INFO : Skipping line #90 with OOV words: shore\twoodland\t3.08\n",
      "INFO : Skipping line #93 with OOV words: lad\twizard\t0.92\n",
      "INFO : Skipping line #95 with OOV words: glass\tmagician\t2.08\n",
      "INFO : Skipping line #97 with OOV words: rooster\tvoyage\t0.62\n",
      "INFO : Skipping line #110 with OOV words: tiger\tfeline\t8.00\n",
      "INFO : Skipping line #111 with OOV words: tiger\tcarnivore\t7.08\n",
      "INFO : Skipping line #112 with OOV words: tiger\tmammal\t6.85\n",
      "INFO : Skipping line #115 with OOV words: tiger\tfauna\t5.62\n",
      "INFO : Skipping line #117 with OOV words: psychology\tpsychiatry\t8.08\n",
      "INFO : Skipping line #121 with OOV words: psychology\tclinic\t6.58\n",
      "INFO : Skipping line #128 with OOV words: psychology\tcognition\t7.48\n",
      "INFO : Skipping line #130 with OOV words: planet\tconstellation\t8.06\n",
      "INFO : Skipping line #133 with OOV words: planet\tgalaxy\t8.11\n",
      "INFO : Skipping line #135 with OOV words: planet\tastronomer\t7.94\n",
      "INFO : Skipping line #138 with OOV words: precedent\tcognition\t2.81\n",
      "INFO : Skipping line #142 with OOV words: precedent\tantecedent\t6.04\n",
      "INFO : Skipping line #144 with OOV words: cup\ttableware\t6.85\n",
      "INFO : Skipping line #146 with OOV words: cup\tartifact\t2.92\n",
      "INFO : Skipping line #169 with OOV words: water\tseepage\t6.56\n",
      "INFO : Skipping line #170 with OOV words: sign\trecess\t2.38\n",
      "INFO : Skipping line #176 with OOV words: president\tmedal\t3.00\n",
      "INFO : Skipping line #182 with OOV words: volunteer\tmotto\t2.56\n",
      "INFO : Skipping line #184 with OOV words: decoration\tvalor\t5.63\n",
      "INFO : Skipping line #187 with OOV words: delay\tracism\t1.19\n",
      "INFO : Skipping line #194 with OOV words: deployment\tdeparture\t4.25\n",
      "INFO : Skipping line #195 with OOV words: deployment\twithdrawal\t5.88\n",
      "INFO : Skipping line #208 with OOV words: reason\thypertension\t2.31\n",
      "INFO : Skipping line #212 with OOV words: hospital\tinfrastructure\t4.63\n",
      "INFO : Skipping line #214 with OOV words: death\tinmate\t5.03\n",
      "INFO : Skipping line #221 with OOV words: OPEC\tcountry\t5.63\n",
      "INFO : Skipping line #236 with OOV words: arrangement\taccommodation\t5.41\n",
      "INFO : Skipping line #244 with OOV words: impartiality\tinterest\t5.16\n",
      "INFO : Skipping line #253 with OOV words: production\thike\t1.75\n",
      "INFO : Skipping line #254 with OOV words: benchmark\tindex\t4.25\n",
      "INFO : Skipping line #261 with OOV words: OPEC\toil\t8.59\n",
      "INFO : Skipping line #267 with OOV words: dollar\tyen\t7.78\n",
      "INFO : Skipping line #271 with OOV words: computer\tsoftware\t8.50\n",
      "INFO : Skipping line #278 with OOV words: investor\tearning\t7.13\n",
      "INFO : Skipping line #283 with OOV words: marathon\tsprint\t7.47\n",
      "INFO : Skipping line #287 with OOV words: seafood\tsea\t7.47\n",
      "INFO : Skipping line #288 with OOV words: seafood\tfood\t8.34\n",
      "INFO : Skipping line #289 with OOV words: seafood\tlobster\t8.70\n",
      "INFO : Skipping line #290 with OOV words: lobster\tfood\t7.81\n",
      "INFO : Skipping line #291 with OOV words: lobster\twine\t5.70\n",
      "INFO : Skipping line #293 with OOV words: video\tarchive\t6.34\n",
      "INFO : Skipping line #297 with OOV words: boxing\tround\t7.61\n",
      "INFO : Skipping line #299 with OOV words: fighting\tdefeating\t7.41\n",
      "INFO : Skipping line #302 with OOV words: summer\tdrought\t7.16\n",
      "INFO : Skipping line #306 with OOV words: environment\tecology\t8.81\n",
      "INFO : Skipping line #310 with OOV words: murder\tmanslaughter\t8.53\n",
      "INFO : Skipping line #318 with OOV words: viewer\tserial\t2.97\n",
      "INFO : Skipping line #324 with OOV words: gender\tequality\t6.41\n",
      "INFO : Skipping line #340 with OOV words: chance\tcredibility\t3.88\n",
      "INFO : Skipping line #341 with OOV words: exhibit\tmemorabilia\t5.31\n",
      "INFO : Skipping line #342 with OOV words: concert\tvirtuoso\t6.81\n",
      "INFO : Skipping line #349 with OOV words: shower\tthunderstorm\t6.31\n",
      "INFO : Pearson correlation coefficient against c:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\test\\test_data\\wordsim353.tsv: 0.1270\n",
      "INFO : Spearman rank-order correlation coefficient against c:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\test\\test_data\\wordsim353.tsv: 0.1905\n",
      "INFO : Pairs with unknown words ratio: 23.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.229461756373937\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "model_evalu= new_model.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "print(float(model_evalu[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PearsonRResult(statistic=0.07493291844688334, pvalue=0.21885481132519732), SignificanceResult(statistic=0.09894828558018688, pvalue=0.10408671839408722), 23.229461756373937)\n"
     ]
    }
   ],
   "source": [
    "# good\n",
    "print(model_evalu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PearsonRResult(statistic=0.0267635554901714, pvalue=0.6609327187257763), SignificanceResult(statistic=0.015647436741891906, pvalue=0.7976309112187147), 23.229461756373937)\n"
     ]
    }
   ],
   "source": [
    "# bad\n",
    "print(model_evalu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.12695793129308622, pvalue=0.036726622889848494)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very good\n",
    "print(model_evalu[0])\n",
    "type(model_evalu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m log_accuracy(section)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "log_accuracy(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : Evaluating word analogies for top 300000 words in the model on c:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\test\\test_data\\./evaluation/wordsim353_annotator2.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\meghd\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\gensim\\\\test\\\\test_data\\\\./evaluation/wordsim353_annotator2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m analogy_scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39;49mevaluate_word_analogies(datapath(\u001b[39m'\u001b[39;49m\u001b[39m./evaluation/wordsim353_annotator2.txt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1335\u001b[0m, in \u001b[0;36mKeyedVectors.evaluate_word_analogies\u001b[1;34m(self, analogies, restrict_vocab, case_insensitive, dummy4unknown, similarity_function)\u001b[0m\n\u001b[0;32m   1333\u001b[0m sections, section \u001b[39m=\u001b[39m [], \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m quadruplets_no \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1335\u001b[0m \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39;49mopen(analogies, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fin:\n\u001b[0;32m   1336\u001b[0m     \u001b[39mfor\u001b[39;00m line_no, line \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(fin):\n\u001b[0;32m   1337\u001b[0m         line \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mto_unicode(line)\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\smart_open\\smart_open_lib.py:177\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m transport_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     transport_params \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 177\u001b[0m fobj \u001b[39m=\u001b[39m _shortcut_open(\n\u001b[0;32m    178\u001b[0m     uri,\n\u001b[0;32m    179\u001b[0m     mode,\n\u001b[0;32m    180\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    181\u001b[0m     buffering\u001b[39m=\u001b[39;49mbuffering,\n\u001b[0;32m    182\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    183\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    184\u001b[0m     newline\u001b[39m=\u001b[39;49mnewline,\n\u001b[0;32m    185\u001b[0m )\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m fobj\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\smart_open\\smart_open_lib.py:363\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m    361\u001b[0m     open_kwargs[\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m errors\n\u001b[1;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[39m=\u001b[39mbuffering, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopen_kwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\meghd\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\gensim\\\\test\\\\test_data\\\\./evaluation/wordsim353_annotator2.txt'"
     ]
    }
   ],
   "source": [
    "analogy_scores = model.wv.evaluate_word_analogies(datapath('./evaluation/wordsim353_annotator2.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79d9b2396b07971306c92d389846a3ac969b302833c083d04b805958db5781b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
