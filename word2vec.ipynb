{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Word2vec From Brown Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 2 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: at sentence #10000, processed 219770 words, keeping 23488 word types\n",
      "INFO : PROGRESS: at sentence #20000, processed 430477 words, keeping 34367 word types\n",
      "INFO : PROGRESS: at sentence #30000, processed 669056 words, keeping 42365 word types\n",
      "INFO : PROGRESS: at sentence #40000, processed 888291 words, keeping 49136 word types\n",
      "INFO : PROGRESS: at sentence #50000, processed 1039920 words, keeping 53024 word types\n",
      "INFO : collected 56057 word types from a corpus of 1161192 raw words and 57340 sentences\n",
      "INFO : Creating a fresh vocabulary\n",
      "INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 15173 unique words (27.07% of original 56057, drops 40884)', 'datetime': '2023-04-12T17:31:41.305785', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1095086 word corpus (94.31% of original 1161192, drops 66106)', 'datetime': '2023-04-12T17:31:41.306783', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO : deleting the raw counts dictionary of 56057 items\n",
      "INFO : sample=0.001 downsamples 42 most-common words\n",
      "INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 781596.5348479215 word corpus (71.4%% of prior 1095086)', 'datetime': '2023-04-12T17:31:41.396545', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO : estimated required memory for 15173 words and 300 dimensions: 44001700 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-12T17:31:41.558111', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 15173 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=20 window=15 shrink_windows=True', 'datetime': '2023-04-12T17:31:41.560108', 'gensim': '4.3.0', 'python': '3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "INFO : EPOCH 0 - PROGRESS: at 19.05% examples, 156457 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 38.57% examples, 158373 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 56.89% examples, 160002 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 68.78% examples, 143915 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0 - PROGRESS: at 93.29% examples, 144935 words/s, in_qsize 0, out_qsize 0\n",
      "INFO : EPOCH 0: training on 1161192 raw words (781573 effective words) took 5.3s, 146738 effective words/s\n",
      "INFO : EPOCH 1 - PROGRESS: at 18.20% examples, 148005 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m neg:\n\u001b[0;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(i,j,k)\n\u001b[1;32m---> 13\u001b[0m     model \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mWord2Vec(brown\u001b[39m.\u001b[39;49msents(),\n\u001b[0;32m     14\u001b[0m                                     vector_size\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m                                     window\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[0;32m     16\u001b[0m                                     negative\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m     17\u001b[0m                                     epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m\n\u001b[0;32m     18\u001b[0m                                     )\n\u001b[0;32m     19\u001b[0m     model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m./model/brown_d(\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m)_w(\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m)_n(\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m).embedding\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m(i,j,k))\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\word2vec.py:430\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file, passes\u001b[39m=\u001b[39m(epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m    429\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_vocab(corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file, trim_rule\u001b[39m=\u001b[39mtrim_rule)\n\u001b[1;32m--> 430\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m    431\u001b[0m         corpus_iterable\u001b[39m=\u001b[39;49mcorpus_iterable, corpus_file\u001b[39m=\u001b[39;49mcorpus_file, total_examples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus_count,\n\u001b[0;32m    432\u001b[0m         total_words\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus_total_words, epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs, start_alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[0;32m    433\u001b[0m         end_alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin_alpha, compute_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m    434\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    435\u001b[0m     \u001b[39mif\u001b[39;00m trim_rule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\word2vec.py:1073\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     callback\u001b[39m.\u001b[39mon_epoch_begin(\u001b[39mself\u001b[39m)\n\u001b[0;32m   1072\u001b[0m \u001b[39mif\u001b[39;00m corpus_iterable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1073\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_epoch(\n\u001b[0;32m   1074\u001b[0m         corpus_iterable, cur_epoch\u001b[39m=\u001b[39mcur_epoch, total_examples\u001b[39m=\u001b[39mtotal_examples,\n\u001b[0;32m   1075\u001b[0m         total_words\u001b[39m=\u001b[39mtotal_words, queue_factor\u001b[39m=\u001b[39mqueue_factor, report_delay\u001b[39m=\u001b[39mreport_delay,\n\u001b[0;32m   1076\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1077\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1078\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_epoch_corpusfile(\n\u001b[0;32m   1079\u001b[0m         corpus_file, cur_epoch\u001b[39m=\u001b[39mcur_epoch, total_examples\u001b[39m=\u001b[39mtotal_examples, total_words\u001b[39m=\u001b[39mtotal_words,\n\u001b[0;32m   1080\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\word2vec.py:1434\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m   1431\u001b[0m     thread\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m-> 1434\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_epoch_progress(\n\u001b[0;32m   1435\u001b[0m     progress_queue, job_queue, cur_epoch\u001b[39m=\u001b[39;49mcur_epoch, total_examples\u001b[39m=\u001b[39;49mtotal_examples,\n\u001b[0;32m   1436\u001b[0m     total_words\u001b[39m=\u001b[39;49mtotal_words, report_delay\u001b[39m=\u001b[39;49mreport_delay, is_corpus_file_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1437\u001b[0m )\n\u001b[0;32m   1439\u001b[0m \u001b[39mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\word2vec.py:1289\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m   1286\u001b[0m unfinished_worker_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\n\u001b[0;32m   1288\u001b[0m \u001b[39mwhile\u001b[39;00m unfinished_worker_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1289\u001b[0m     report \u001b[39m=\u001b[39m progress_queue\u001b[39m.\u001b[39;49mget()  \u001b[39m# blocks if workers too slow\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[39mif\u001b[39;00m report \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# a thread reporting that it finished\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m         unfinished_worker_count \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[0;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from nltk.corpus import brown\n",
    "# import logging\n",
    "# logging.basicConfig(\n",
    "#     format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "dim = [25, 100, 300]\n",
    "wind = [2, 7, 15]\n",
    "neg = [1, 7, 20]\n",
    "for i in dim:\n",
    "    for j in wind:  \n",
    "        for k in neg:\n",
    "            print(i,j,k)\n",
    "            model = gensim.models.Word2Vec(brown.sents(),\n",
    "                                            vector_size=i,\n",
    "                                            window=j,\n",
    "                                            negative=k,\n",
    "                                            epochs=5\n",
    "                                            )\n",
    "            model.save('./model/brown_d(%d)_w(%d)_n(%d).embedding' %(i,j,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Corpus' from 'mittens' (c:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\mittens\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mword2vec\u001b[39;00m \u001b[39mimport\u001b[39;00m Text8Corpus\n\u001b[0;32m      3\u001b[0m \u001b[39m# from glove import Glove\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmittens\u001b[39;00m \u001b[39mimport\u001b[39;00m GloVe,Corpus\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m brown\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Corpus' from 'mittens' (c:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\mittens\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "# from glove import Glove\n",
    "from mittens import GloVe\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "don't know how to handle uri [['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sentences \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(Text8Corpus(brown\u001b[39m.\u001b[39;49msents()),\u001b[39mNone\u001b[39;49;00m))\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\word2vec.py:2041\u001b[0m, in \u001b[0;36mText8Corpus.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2037\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   2038\u001b[0m     \u001b[39m# the entire corpus is one gigantic line -- there are no sentence marks at all\u001b[39;00m\n\u001b[0;32m   2039\u001b[0m     \u001b[39m# so just split the sequence of tokens arbitrarily: 1 sentence = 1000 tokens\u001b[39;00m\n\u001b[0;32m   2040\u001b[0m     sentence, rest \u001b[39m=\u001b[39m [], \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m-> 2041\u001b[0m     \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfname, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fin:\n\u001b[0;32m   2042\u001b[0m         \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   2043\u001b[0m             text \u001b[39m=\u001b[39m rest \u001b[39m+\u001b[39m fin\u001b[39m.\u001b[39mread(\u001b[39m8192\u001b[39m)  \u001b[39m# avoid loading the entire file (=1 line) into RAM\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\smart_open\\smart_open_lib.py:224\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n\u001b[0;32m    222\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(ve\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> 224\u001b[0m binary \u001b[39m=\u001b[39m _open_binary_stream(uri, binary_mode, transport_params)\n\u001b[0;32m    225\u001b[0m decompressed \u001b[39m=\u001b[39m so_compression\u001b[39m.\u001b[39mcompression_wrapper(binary, binary_mode, compression)\n\u001b[0;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mor\u001b[39;00m explicit_encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\meghd\\Anaconda3\\envs\\nlp\\lib\\site-packages\\smart_open\\smart_open_lib.py:396\u001b[0m, in \u001b[0;36m_open_binary_stream\u001b[1;34m(uri, mode, transport_params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[39mreturn\u001b[39;00m fobj\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(uri, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 396\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdon\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt know how to handle uri \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mrepr\u001b[39m(uri))\n\u001b[0;32m    398\u001b[0m scheme \u001b[39m=\u001b[39m _sniff_scheme(uri)\n\u001b[0;32m    399\u001b[0m submodule \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39mget_transport(scheme)\n",
      "\u001b[1;31mTypeError\u001b[0m: don't know how to handle uri [['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
     ]
    }
   ],
   "source": [
    "sentences = list(itertools.islice(Text8Corpus(brown.sents()),None))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_evalu):\n",
    "    acc = round(model_evalu[0][0],6)\n",
    "    acc = acc*100\n",
    "    return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions For Evaluation of Bats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import random\n",
    "import os\n",
    "\n",
    "def collect(model):\n",
    "    if type(model) is dict:\n",
    "        vocab = [k for k in model.keys()]\n",
    "    else:\n",
    "        vocab = [k for k in model.wv.key_to_index.keys()]\n",
    "\n",
    "    indices = {}\n",
    "    for i in range(len(vocab)): indices[vocab[i]] = i\n",
    "        \n",
    "    matrix = []\n",
    "    for w in vocab:\n",
    "        matrix.append(model.wv[w])\n",
    "    return np.array(matrix), vocab, indices\n",
    "\n",
    "def eval_bats_file(model, matrix, vocab, indices, f, repeat=False, multi=0):\n",
    "    pairs = [line.strip().split() for line in open(f, 'r').readlines()]\n",
    "\n",
    "    # discard pairs that are not in our vocabulary\n",
    "    pairs = [[p[0], p[1].split('/')] for p in pairs if p[0] in model.wv]\n",
    "    pairs = [[p[0], [w for w in p[1] if w in model.wv]] for p in pairs]\n",
    "    pairs = [p for p in pairs if len(p[1]) > 0]\n",
    "    if len(pairs) <= 1: return None\n",
    "\n",
    "    transposed = np.transpose(np.array([x / norm(x) for x in matrix]))\n",
    "    \n",
    "    if not multi:\n",
    "        qa = []\n",
    "        qb = []\n",
    "        qc = []\n",
    "        targets = []\n",
    "        exclude = []\n",
    "        groups = []\n",
    "        for i in range(len(pairs)):\n",
    "            j = random.randint(0, len(pairs) - 2)\n",
    "            if j >= i: j += 1\n",
    "            a = model.wv[pairs[i][0]]\n",
    "            c = model.wv[pairs[j][0]]\n",
    "            for bw in pairs[i][1]:\n",
    "                qa.append(a)\n",
    "                qb.append(model.wv[bw])\n",
    "                qc.append(c)\n",
    "                groups.append(i)\n",
    "                targets.append(pairs[j][1])\n",
    "                exclude.append([pairs[i][0], bw, pairs[j][0]])\n",
    "\n",
    "        for queries in [qa, qb, qc]:\n",
    "            queries = np.array([x / norm(x) for x in queries])\n",
    "        sa = np.matmul(qa, transposed) + .0001\n",
    "        sb = np.matmul(qb, transposed)\n",
    "        sc = np.matmul(qc, transposed)\n",
    "        sims = sb + sc - sa\n",
    "        # exclude original query words from candidates\n",
    "        for i in range(len(exclude)):\n",
    "            for w in exclude[i]:\n",
    "                sims[i][indices[w]] = 0\n",
    "\n",
    "    else:\n",
    "        offsets = []\n",
    "        exclude = []\n",
    "        preds = []\n",
    "        targets = []\n",
    "        groups = []\n",
    "        \n",
    "        for i in range(len(pairs) // multi):\n",
    "            qa = [pairs[j][0] for j in range(len(pairs)) if j - i not in range(multi)]\n",
    "            qb = [[w for w in pairs[j][1] if w in model] for j in range(len(pairs)) if j - i not in range(multi)]\n",
    "            qbs = []\n",
    "            for ws in qb: qbs += ws\n",
    "            a = np.mean([model[w] for w in qa], axis=0)\n",
    "            b = np.mean([np.mean([model[w] for w in ws], axis=0) for ws in qb], axis=0)\n",
    "            a = a / norm(a)\n",
    "            b = b / norm(b)\n",
    "\n",
    "            for k in range(multi):\n",
    "                c = model[pairs[i + k][0]]\n",
    "                c = c / norm(c)\n",
    "                offset = b + c - a\n",
    "                offsets.append(offset / norm(offset))\n",
    "                targets.append(pairs[i + k][1])\n",
    "                exclude.append(qa + qbs + [pairs[i + k][0]])\n",
    "                groups.append(len(groups))\n",
    "\n",
    "        print(np.shape(transposed))\n",
    "        sims = np.matmul(np.array(offsets), transposed)\n",
    "        print(np.shape(sims))\n",
    "        for i in range(len(exclude)):\n",
    "            for w in exclude[i]:\n",
    "                sims[i][indices[w]] = 0\n",
    "\n",
    "    preds = [vocab[np.argmax(x)] for x in sims]\n",
    "    accs = [1 if preds[i].lower() in targets[i] else 0 for i in range(len(preds))]\n",
    "    regrouped = np.zeros(np.max(groups) + 1)\n",
    "    for a, g in zip(accs, groups):\n",
    "        regrouped[g] = max(a, regrouped[g])\n",
    "    return np.mean(regrouped)\n",
    "\n",
    "def eval_bats(model, matrix, vocab, indices):\n",
    "    accs = {}\n",
    "    base = './evaluation/bats'\n",
    "    for dr in os.listdir('./evaluation/bats'):\n",
    "        if os.path.isdir(os.path.join(base, dr)):\n",
    "            dk = dr.split('_', 1)[1].lower()\n",
    "            accs[dk] = []\n",
    "            for f in os.listdir(os.path.join(base, dr)):\n",
    "                accs[f.split('.')[0]] = eval_bats_file(model, matrix, vocab, indices, os.path.join(base, dr, f))\n",
    "                accs[dk].append(accs[f.split('.')[0]])\n",
    "            accs[dk] = [a for a in accs[dk] if a is not None]\n",
    "            accs[dk] = np.mean(accs[dk]) if len(accs[dk]) > 0 else None\n",
    "\n",
    "    accs['total'] = np.mean([accs[k] for k in accs.keys() if accs[k] is not None])\n",
    "\n",
    "    return accs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Bats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalu_bats(model):\n",
    "    bats_cat_1 = \"lexicographic_semantics\"\n",
    "    bats_cat_2 = \"E10 [male - female]\"\n",
    "    bats_cat_3 = \"total\"\n",
    "\n",
    "    matrix, vocab, indices = collect(model)\n",
    "    bats = eval_bats(model, matrix, vocab, indices)\n",
    "    bat1 = round(bats[bats_cat_1],6)\n",
    "    bat2 = round(bats[bats_cat_2],6)\n",
    "    bat3 = round(bats[bats_cat_3],6)\n",
    "    result_bats = [bat1,bat2,bat3]\n",
    "    \n",
    "    return result_bats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialing Tabel Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Algorithm', 'Win', 'Dim', 'NS','wordsim353','BAT1','BAT2','Bat3','win353']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare accuracy of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 2 1 => wordsim353:  13.0802  win353:  12.2082  BAT1:  0.025163 BAT2  0.285714 BAT3 0.02938\n",
      "25 2 7 => wordsim353:  13.0435  win353:  12.2053  BAT1:  0.022627 BAT2  0.214286 BAT3 0.030254\n",
      "25 2 20 => wordsim353:  13.05  win353:  12.185  BAT1:  0.031017 BAT2  0.142857 BAT3 0.028315\n",
      "25 7 1 => wordsim353:  12.8822  win353:  12.1052  BAT1:  0.040281 BAT2  0.214286 BAT3 0.033563\n",
      "25 7 7 => wordsim353:  12.778500000000001  win353:  12.0117  BAT1:  0.011525 BAT2  0.285714 BAT3 0.025896\n",
      "25 7 20 => wordsim353:  13.1352  win353:  12.3628  BAT1:  0.030755 BAT2  0.142857 BAT3 0.035561\n",
      "25 15 1 => wordsim353:  12.97  win353:  12.0762  BAT1:  0.031715 BAT2  0.214286 BAT3 0.032998\n",
      "25 15 7 => wordsim353:  13.013  win353:  12.1969  BAT1:  0.03183 BAT2  0.285714 BAT3 0.025944\n",
      "25 15 20 => wordsim353:  12.958300000000001  win353:  12.1617  BAT1:  0.022838 BAT2  0.071429 BAT3 0.018002\n",
      "100 2 1 => wordsim353:  12.948699999999999  win353:  12.1829  BAT1:  0.045067 BAT2  0.142857 BAT3 0.038776\n",
      "100 2 7 => wordsim353:  13.054499999999999  win353:  12.1664  BAT1:  0.022903 BAT2  0.214286 BAT3 0.029635\n",
      "100 2 20 => wordsim353:  12.978200000000001  win353:  12.1892  BAT1:  0.046354 BAT2  0.214286 BAT3 0.034614\n",
      "100 7 1 => wordsim353:  13.0822  win353:  12.2554  BAT1:  0.035774 BAT2  0.142857 BAT3 0.025725\n",
      "100 7 7 => wordsim353:  12.985199999999999  win353:  12.2831  BAT1:  0.023338 BAT2  0.142857 BAT3 0.025359\n",
      "100 7 20 => wordsim353:  13.0404  win353:  12.1895  BAT1:  0.024045 BAT2  0.071429 BAT3 0.021891\n",
      "100 15 1 => wordsim353:  12.8611  win353:  12.0378  BAT1:  0.042366 BAT2  0.214286 BAT3 0.032731\n",
      "100 15 7 => wordsim353:  13.092400000000001  win353:  12.2846  BAT1:  0.019235 BAT2  0.142857 BAT3 0.025403\n",
      "100 15 20 => wordsim353:  13.2239  win353:  12.3907  BAT1:  0.019338 BAT2  0.071429 BAT3 0.021746\n",
      "300 2 1 => wordsim353:  12.8157  win353:  11.975900000000001  BAT1:  0.023542 BAT2  0.142857 BAT3 0.021384\n",
      "300 2 7 => wordsim353:  12.7666  win353:  12.0257  BAT1:  0.047588 BAT2  0.071429 BAT3 0.029798\n",
      "300 2 20 => wordsim353:  12.9012  win353:  12.0658  BAT1:  0.009524 BAT2  0.428571 BAT3 0.035396\n",
      "300 7 1 => wordsim353:  12.772  win353:  11.9498  BAT1:  0.048492 BAT2  0.285714 BAT3 0.03865\n",
      "300 7 7 => wordsim353:  12.779599999999999  win353:  11.9841  BAT1:  0.033186 BAT2  0.285714 BAT3 0.035055\n",
      "300 7 20 => wordsim353:  13.0596  win353:  12.141499999999999  BAT1:  0.029502 BAT2  0.142857 BAT3 0.025114\n",
      "300 15 1 => wordsim353:  12.725900000000001  win353:  12.127699999999999  BAT1:  0.02995 BAT2  0.0 BAT3 0.027936\n",
      "300 15 7 => wordsim353:  12.9253  win353:  12.2627  BAT1:  0.034668 BAT2  0.142857 BAT3 0.03146\n",
      "300 15 20 => wordsim353:  12.997700000000002  win353:  12.0591  BAT1:  0.033343 BAT2  0.071429 BAT3 0.032719\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "data = []\n",
    "dim = [25, 100, 300]\n",
    "wind = [2, 7, 15]\n",
    "neg = [1, 7, 20]\n",
    "for i in dim:\n",
    "    for j in wind:\n",
    "        for k in neg:\n",
    "            new_model = gensim.models.Word2Vec.load('./model/brown_d(%d)_w(%d)_n(%d).embedding' %(i,j,k))\n",
    "            model_evalu_wordsim353= new_model.wv.evaluate_word_pairs('./evaluation/wordsim353.tsv')\n",
    "            model_evalu_win353= new_model.wv.evaluate_word_pairs('./evaluation/win353.tsv')\n",
    "            bats_list = evalu_bats(new_model)\n",
    "            data.append(['Word2Vec',i,j,k,evaluation(model_evalu_wordsim353),bats_list[0],bats_list[1],bats_list[2],evaluation(model_evalu_win353)],)\n",
    "            print(i,j,k,\"=>\",\"wordsim353: \",evaluation(model_evalu_wordsim353),\n",
    "                  \" win353: \",evaluation(model_evalu_win353),\n",
    "                  \" BAT1: \",bats_list[0],\n",
    "                  \"BAT2 \",bats_list[1],\n",
    "                  \"BAT3\",bats_list[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make accuracy as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('./result/models_results.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write the data\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cells": {
          "align": "left",
          "fill": {
           "color": "lavender"
          },
          "values": [
           [
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec",
            "Word2Vec"
           ],
           [
            25,
            25,
            25,
            25,
            25,
            25,
            25,
            25,
            25,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            300,
            300,
            300,
            300,
            300,
            300,
            300,
            300,
            300
           ],
           [
            2,
            2,
            2,
            7,
            7,
            7,
            15,
            15,
            15,
            2,
            2,
            2,
            7,
            7,
            7,
            15,
            15,
            15,
            2,
            2,
            2,
            7,
            7,
            7,
            15,
            15,
            15
           ],
           [
            1,
            7,
            20,
            1,
            7,
            20,
            1,
            7,
            20,
            1,
            7,
            20,
            1,
            7,
            20,
            1,
            7,
            20,
            1,
            7,
            20,
            1,
            7,
            20,
            1,
            7,
            20
           ],
           [
            13.0802,
            13.0435,
            13.05,
            12.8822,
            12.7785,
            13.1352,
            12.97,
            13.013,
            12.9583,
            12.9487,
            13.0545,
            12.9782,
            13.0822,
            12.9852,
            13.0404,
            12.8611,
            13.0924,
            13.2239,
            12.8157,
            12.7666,
            12.9012,
            12.772,
            12.7796,
            13.0596,
            12.7259,
            12.9253,
            12.997700000000002
           ],
           [
            0.025163,
            0.022627,
            0.031017,
            0.040281,
            0.011525,
            0.030755,
            0.031715,
            0.03183,
            0.022838,
            0.045067,
            0.022903,
            0.046354,
            0.035774,
            0.023338,
            0.024045,
            0.042366,
            0.019235,
            0.019338,
            0.023542,
            0.047588,
            0.009524,
            0.048492,
            0.033186,
            0.029502,
            0.02995,
            0.034668,
            0.033343
           ],
           [
            0.285714,
            0.214286,
            0.142857,
            0.214286,
            0.285714,
            0.142857,
            0.214286,
            0.285714,
            0.071429,
            0.142857,
            0.214286,
            0.214286,
            0.142857,
            0.142857,
            0.071429,
            0.214286,
            0.142857,
            0.071429,
            0.142857,
            0.071429,
            0.428571,
            0.285714,
            0.285714,
            0.142857,
            0,
            0.142857,
            0.071429
           ],
           [
            0.02938,
            0.030254,
            0.028315,
            0.033563,
            0.025896,
            0.035561,
            0.032998,
            0.025944,
            0.018002,
            0.038776,
            0.029635,
            0.034614,
            0.025725,
            0.025359,
            0.021891,
            0.032731,
            0.025403,
            0.021746,
            0.021384,
            0.029798,
            0.035396,
            0.03865,
            0.035055,
            0.025114,
            0.027936,
            0.03146,
            0.032719
           ],
           [
            12.2082,
            12.2053,
            12.185,
            12.1052,
            12.0117,
            12.3628,
            12.0762,
            12.1969,
            12.1617,
            12.1829,
            12.1664,
            12.1892,
            12.2554,
            12.2831,
            12.1895,
            12.0378,
            12.2846,
            12.3907,
            11.9759,
            12.0257,
            12.0658,
            11.9498,
            11.9841,
            12.1415,
            12.1277,
            12.2627,
            12.0591
           ]
          ]
         },
         "header": {
          "align": "left",
          "fill": {
           "color": "paleturquoise"
          },
          "values": [
           "Algorithm",
           "Win",
           "Dim",
           "NS",
           "wordsim353",
           "BAT1",
           "BAT2",
           "Bat3",
           "win353"
          ]
         },
         "type": "table"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "# ['Algorithm', 'Win', 'Dim', 'NS','wordsim353','BAT1','BAT2','Bat3','win353']\n",
    "df = pd.read_csv('./result/models_results.csv')\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(df.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[df.Algorithm, df.Win, df.Dim, df.NS, df.wordsim353,df.BAT1,df.BAT2,df.Bat3, df.win353],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editional Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one time used \n",
    "# convert csv to tsv\n",
    "import re\n",
    " \n",
    "# reading given tsv file\n",
    "with open(\"win353.csv\", 'r') as myfile: \n",
    "  with open(\"win353.tsv\", 'w') as csv_file:\n",
    "    for line in myfile:\n",
    "       \n",
    "      # Replace every tab with comma\n",
    "      fileContent = re.sub(\",\", \"\\t\", line)\n",
    "       \n",
    "      # Writing into csv file\n",
    "      csv_file.write(fileContent)\n",
    " \n",
    "# output\n",
    "print(\"Successfully made tsv file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(brown.sents())\n",
    "model.save('./model/brown.embedding')\n",
    "new_model = gensim.models.Word2Vec.load('./model/brown.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "new_model = gensim.models.Word2Vec.load('./model/brown.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.zeros(shape=(50,len(new_model.wv['university'])))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.wv.most_similar(\"university\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "model_evalu= new_model.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "print(float(model_evalu[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_NAME = 'models_eval.csv'\n",
    "\n",
    "bats_cat_1 = \"lexicographic_semantics\"\n",
    "bats_cat_2 = \"E10 [male - female]\"\n",
    "bats_cat_3 = \"total\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79d9b2396b07971306c92d389846a3ac969b302833c083d04b805958db5781b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
